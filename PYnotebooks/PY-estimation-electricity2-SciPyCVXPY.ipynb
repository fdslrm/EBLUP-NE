{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| [Table of Contents](#table_of_contents) | [Data and model](#data_and_model) | [Natural estimators](#natural_estimators) |  [NN-DOOLSE, MLE](#doolse) | [NN-MDOOLSE, REMLE](#mdoolse) | [References](#references) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors:** Jozef Hanč, Martina Hančová, Andrej Gajdoš  <br> *[Faculty of Science](https://www.upjs.sk/en/faculty-of-science/?prefferedLang=EN), P. J. Šafárik University in Košice, Slovakia* <br> emails: [martina.hancova@upjs.sk](mailto:martina.hancova@upjs.sk)\n",
    "***\n",
    "**<font size=6 color=brown> EBLUP-NE for electricity consumption 2</font>**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> Python-based computational tools - </font>  **<font size=4>SciPy, CVXPY</font>**  \n",
    "<a id=table_of_contents></a>\n",
    "###  Table of Contents \n",
    "* [Data and model](#data_and_model) - data and model description of empirical data\n",
    "* [Natural estimators](#natural_estimators) - EBLUPNE based on NE\n",
    "* [NN-DOOLSE, MLE](#doolse) - EBLUPNE based on nonnegative DOOLSE (same as MLE)\n",
    "* [NN-MDOOLSE, REMLE](#mdoolse) - EBLUPNE based on nonnegative MDOOLSE (same as REMLE)\n",
    "* [References](#references)\n",
    "\n",
    "**To get back to the contents, use <font color=brown>the Home key</font>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPY: A Python-Embedded Modeling Language for Convex Optimization \n",
    "\n",
    "* _Purpose_: scientific Python library for solving convex optimization tasks\n",
    "* _Version_: 1.0.1, 2018\n",
    "* _URL_: https://www.cvxpy.org/\n",
    "* _Computational parameters_ of CVXPY:\n",
    ">   * <font size=2> *solver* - the convex optimization solver ECOS, OSQP, and SCS chosen according to the given problem\n",
    "    * **OSQP** for convex quadratic problems\n",
    "        * `max_iter` - maximum number of iterations (default: 10000).\n",
    "        * `eps_abs` - absolute accuracy (default: 1e-4).\n",
    "        * `eps_rel` - relative accuracy (default: 1e-4).\n",
    "    * **ECOS** for convex second-order cone problems \n",
    "        * `max_iters` - maximum number of iterations (default: 100).\n",
    "        * `abstol` - absolute accuracy (default: 1e-7).\n",
    "        * `reltol` - relative accuracy (default: 1e-6).\n",
    "        * `feastol` - tolerance for feasibility conditions (default: 1e-7).\n",
    "        * `abstol_inacc` - absolute accuracy for inaccurate solution (default: 5e-5).\n",
    "        * `reltol_inacc` - relative accuracy for inaccurate solution (default: 5e-5).\n",
    "        * `feastol_inacc` - tolerance for feasibility condition for inaccurate solution (default: 1e-4).\n",
    "    * **SCS** for large-scale convex cone problems\n",
    "        * `max_iters` - maximum number of iterations (default: 2500).\n",
    "        * `eps` - convergence tolerance (default: 1e-4).\n",
    "        * `alpha` - relaxation parameter (default: 1.8).\n",
    "        * `scale` - balance between minimizing primal and dual residual (default: 5.0).\n",
    "        * `normalize` - whether to precondition data matrices (default: True).\n",
    "        * `use_indirect` - whether to use indirect solver for KKT sytem (instead of direct) (default: True).<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy - NumPy, Pandas\n",
    "* Numpy is the fundamental Python library of SciPy ecosystem for fast scientific computing with large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.  \n",
    "* default precision: double floating-point precision $\\text{eps}<10^{-15}$\n",
    "* Pandas is the Python library providing high-performance, easy to use data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:32.915000Z",
     "start_time": "2019-05-18T17:59:32.245000Z"
    }
   },
   "outputs": [],
   "source": [
    "import cvxpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import platform as pt\n",
    "\n",
    "from cvxpy import *\n",
    "from math import cos, sin\n",
    "from numpy.linalg import inv, norm\n",
    "from itertools import product\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "np.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:32.931000Z",
     "start_time": "2019-05-18T17:59:32.919000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvxpy:1.0.1\n",
      "numpy:1.16.3\n",
      "pandas:0.24.2\n",
      "python:2.7.16\n"
     ]
    }
   ],
   "source": [
    "# software versions\n",
    "print('cvxpy:'+cvxpy.__version__)\n",
    "print('numpy:'+np.__version__)\n",
    "print('pandas:'+pd.__version__)\n",
    "print('python:'+pt.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=data_and_model></a>\n",
    "# <font color=brown>Data and Toy Model 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this FDSLRM application, we model the econometric time series data set, representing the hours observations of the consumption of the electric energy in some department store. The number of time series observations is $n=24$. The data and model were adapted from _Štulajter & Witkovský, 2004_.\n",
    "\n",
    "The consumption data can be fitted by the following Gaussian orthogonal FDSLRM:\n",
    "\n",
    "$ \n",
    "\\begin{array}{rl}\n",
    "& X(t) & \\!  = \\! & \\beta_1+\\beta_2\\cos\\left(\\tfrac{2\\pi t}{24}\\right)+\\beta_3\\sin\\left(\\tfrac{2\\pi t}{24}\\right) +\\\\\n",
    "&      &         & +Y_1\\cos\\left(\\tfrac{2\\pi t\\cdot 2}{24}\\right)+Y_2\\sin\\left(\\tfrac{2\\pi t\\cdot 2}{24}\\right)+\\\\\n",
    "&      &         & +Y_3\\cos\\left(\\tfrac{2\\pi t\\cdot 3}{24}\\right)+Y_4\\sin\\left(\\tfrac{2\\pi t\\cdot 3}{24}\\right)\n",
    "+w(t), \\, t\\in \\mathbb{N},\n",
    "\\end{array}\n",
    "$ \n",
    "\n",
    "where $\\boldsymbol{\\beta}=(\\beta_1,\\,\\beta_2,\\,\\beta_3)' \\in \\mathbb{R}^3\\,,\\mathbf{Y} = (Y_1, Y_2, Y_3, Y_4)' \\sim \\mathcal{N}_4(\\boldsymbol{0}, \\mathrm{D})\\,, w(t) \\sim \\mathcal{iid}\\, \\mathcal{N} (0, \\sigma_0^2)\\,, \\boldsymbol{\\nu}= (\\sigma_0^2, \\sigma_1^2, \\sigma_2^2, \\sigma_3^2, \\sigma_4^2) \\in \\mathbb{R}_{+}^5.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy(Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:32.947000Z",
     "start_time": "2019-05-18T17:59:32.937000Z"
    }
   },
   "outputs": [],
   "source": [
    "# data - time series observation\n",
    "data = [40.3,40.7,38.5,37.9,38.6,41.1,45.2,45.7,46.7,46.5,\n",
    "        45.2,45.1,45.8,46.3,47.5,48.5,49.1,51.7,50.6,48.0,\n",
    "        44.7,41.2,40.0,40.3]\n",
    "\n",
    "# observation x as matrix\n",
    "x = np.mat(data).T\n",
    "xc = x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:32.972000Z",
     "start_time": "2019-05-18T17:59:32.953000Z"
    }
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "n, k, l = 24, 3, 4\n",
    "\n",
    "# significant frequencies\n",
    "om1, om2, om3 = 2*np.pi/24, 2*np.pi/12, 2*np.pi/8\n",
    "\n",
    "# model - design matrices F', F, V',V\n",
    "Fc = np.mat([[1 for t in range(1,n+1)],\n",
    "             [cos(om1*t) for t in range(1,n+1)],\n",
    "             [sin(om1*t) for t in range(1,n+1)]])\n",
    "Vc = np.mat([[cos(om2*t) for t in range(1,n+1)],\n",
    "             [sin(om2*t) for t in range(1,n+1)],\n",
    "             [cos(om3*t) for t in range(1,n+1)],\n",
    "             [sin(om3*t) for t in range(1,n+1)]])\n",
    "F, V = Fc.T, Vc.T\n",
    "\n",
    "# columns vj of V and their squared norm ||vj||^2\n",
    "vv = lambda j: V[:,j-1]\n",
    "nv2 = lambda j: np.trace(vv(j).T*vv(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.012000Z",
     "start_time": "2019-05-18T17:59:32.979000Z"
    }
   },
   "outputs": [],
   "source": [
    "# auxiliary matrices and vectors\n",
    "\n",
    "# Gram matrices GF, GV\n",
    "GF, GV = Fc*F, Vc*V\n",
    "InvGF, InvGV = inv(GF), inv(GV)\n",
    "\n",
    "# projectors PF, MF, PV, MV\n",
    "In = np.identity(n)\n",
    "PF = F*InvGF*Fc\n",
    "PV = V*InvGV*Vc\n",
    "MF, MV = In-PF, In-PV\n",
    "\n",
    "# residuals e, e'\n",
    "e = MF*x\n",
    "ec = e.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.036000Z",
     "start_time": "2019-05-18T17:59:33.017000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[-1.7608940093e-15,  2.8729739758e-16, -2.1437508791e-15,\n",
       "          -1.1445501570e-15],\n",
       "         [-2.2459749128e-15, -4.8985871966e-16, -3.0728232692e-15,\n",
       "          -9.2250555206e-16],\n",
       "         [-7.1900085738e-16, -1.6653345369e-16,  1.1428494210e-15,\n",
       "           5.6504106949e-16]]),\n",
       " matrix([[ 1.2000000000e+01,  3.4280854881e-16,  5.5511151231e-16,\n",
       "          -2.7331895238e-15],\n",
       "         [ 3.4280854881e-16,  1.2000000000e+01, -4.8985871966e-16,\n",
       "           8.3266726847e-16],\n",
       "         [ 5.5511151231e-16, -4.8985871966e-16,  1.2000000000e+01,\n",
       "           1.4856579698e-15],\n",
       "         [-2.7331895238e-15,  8.3266726847e-16,  1.4856579698e-15,\n",
       "           1.2000000000e+01]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# orthogonality condition\n",
    "Fc*V, GV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=natural_estimators></a>\n",
    "# <font color=brown> Natural estimators</font>\n",
    "\n",
    "## ANALYTICALLY \n",
    "using formula (4.1) from _Hancova et al 2019_\n",
    "\n",
    ">$\n",
    "\\renewcommand{\\arraystretch}{1.4}\n",
    "\\breve{\\boldsymbol{\\nu}}(\\mathbf{e}) =\n",
    "\\begin{pmatrix}\n",
    "\\tfrac{1}{n-k-l}\\,\\mathbf{e}'\\,\\mathrm{M_V}\\,\\mathbf{e} \\\\\n",
    "(\\mathbf{e}'\\mathbf{v}_1)^2/||\\mathbf{v}_1||^4 \\\\\n",
    "\\vdots \\\\\n",
    "(\\mathbf{e}'\\mathbf{v}_l)^2/||\\mathbf{v}_l||^4\n",
    "\\end{pmatrix} \n",
    "$\n",
    "\n",
    "## $\\boldsymbol{1^{st}}$ stage of EBLUP-NE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy(Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.049000Z",
     "start_time": "2019-05-18T17:59:33.040000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0930446920400416, 2.9657173646433215, 1.7618587371177754, 0.3719349745059175, 1.8634794260764524] 4.087207309639801\n"
     ]
    }
   ],
   "source": [
    "# NE according to formula (4.1)\n",
    "NE0 = [1/(n-k-l)*np.trace(ec*MV*e)]\n",
    "NEj = [(np.trace(ec*vv(j))/nv2(j))**2 for j in range(1,l+1)] \n",
    "NE = NE0+NEj\n",
    "print(NE, norm(NE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPY\n",
    "\n",
    "\n",
    "NE as a convex optimization problem\n",
    "\n",
    ">$\n",
    "\\begin{array}{ll} \n",
    "\\textit{minimize}    & \\quad \n",
    "f_0(\\boldsymbol{\\nu})=||\\mathbf{e}\\mathbf{e}' - \\mathrm{VDV'}||^2+||\\mathrm{M_V}\\mathbf{e}\\mathbf{e}'\\mathrm{M_V}-\\nu_0\\mathrm{M_F}\\mathrm{M_V}||^2 \\\\[6pt]\n",
    "\\textit{subject to}  & \\quad \\boldsymbol{\\nu} = \\left(\\nu_0, \\ldots, \\nu_l\\right)'\\in [0, \\infty)^{l+1} \n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.112000Z",
     "start_time": "2019-05-18T17:59:33.055000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEcvx = [1.093044692  2.9657173646 1.7618587371 0.3719349745 1.8634794261]  norm =  4.0872073096398\n"
     ]
    }
   ],
   "source": [
    "# the optimization variable, objective function\n",
    "v = Variable(l+1)\n",
    "fv = sum_squares(e*ec-V*diag(v[1:])*Vc)+sum_squares(MV*e*ec*MV-v[0]*MF*MV)\n",
    "\n",
    "# the optimization problem for NE\n",
    "objective = Minimize(fv)\n",
    "constraints = [v >= 0]\n",
    "prob = Problem(objective,constraints)\n",
    "\n",
    "# solve the NE problem\n",
    "prob.solve()\n",
    "NEcvx = v.value\n",
    "print('NEcvx =', NEcvx, ' norm = ', norm(NEcvx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\boldsymbol{2^{nd}}$ stage of EBLUP-NE\n",
    "using formula (3.10) from _Hancova et al 2019_.\n",
    ">$\n",
    "\\mathring{\\nu}_j = \\rho_j^2 \\breve{\\nu}_j; j = 0,1 \\ldots, l\\\\\n",
    "\\rho_0 = 1, \\rho_j = \\dfrac{\\hat{\\nu}_j||\\mathbf{v}_j||^2}{\\hat{\\nu}_0+\\hat{\\nu}_j||\\mathbf{v}_j||^2} \n",
    "$\n",
    ">\n",
    ">where $\\boldsymbol{\\breve{\\nu}}$ are NE,  $\\boldsymbol{\\hat{\\nu}}$ are initial estimates for EBLUP-NE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy(Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.126000Z",
     "start_time": "2019-05-18T17:59:33.118000Z"
    }
   },
   "outputs": [],
   "source": [
    "# EBLUP-NE based on formula (3.9)\n",
    "rho2 = lambda est: [1]+ [ (est[j]*nv2(j)/(est[0]+est[j]*nv2(j)))**2 for j in range(1,l+1) ]\n",
    "EBLUPNE = lambda est: [rho2(est)[j]*NE[j] for j in range(l+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.138000Z",
     "start_time": "2019-05-18T17:59:33.131000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0.9412916672125289, 0.9041005620343124, 0.645254027434808, 0.908967404573379]\n"
     ]
    }
   ],
   "source": [
    "# numerical results\n",
    "print(rho2(NE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.156000Z",
     "start_time": "2019-05-18T17:59:33.144000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0930446920400416, 2.7916050426462595, 1.5928974744532447, 0.2399925402438059, 1.6938420573966029] 3.801555617352282\n"
     ]
    }
   ],
   "source": [
    "print(EBLUPNE(NE),norm(EBLUPNE(NE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross-checking \n",
    "using formula (3.6) for general FDSLRM from _Hancova et al 2019_.\n",
    ">$\n",
    "\\mathring{\\nu}_0 = \\breve{\\nu}_0, \\mathring{\\nu}_j = (\\mathbf{Y}^*)_j^2, j = 1, 2, \\ldots, l \\\\\n",
    "\\mathbf{Y}^* = \\mathbb{T}\\mathbf{X} \\mbox{ with } \\mathbb{T} = \\mathrm{D}\\mathbb{U}^{-1}\\mathrm{V}'\\mathrm{M_F}, \\mathbb{U} = \\mathrm{V}'\\mathrm{M_F}\\mathrm{V}\\mathrm{D} + \\nu_0 \\mathrm{I}_l\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.170000Z",
     "start_time": "2019-05-18T17:59:33.161000Z"
    }
   },
   "outputs": [],
   "source": [
    "def EBLUPNEgen(est):\n",
    "    D = np.diag(est[1:])\n",
    "    U = Vc*MF*V*D + est[0]*np.identity(l)\n",
    "    T = D*inv(U)*Vc*MF\n",
    "    eest = np.vstack((np.matrix(NE[0]),np.multiply(T*x, T*x)))\n",
    "    return np.array(eest).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.185000Z",
     "start_time": "2019-05-18T17:59:33.175000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0930446920400416, 2.791605042646258, 1.592897474453243, 0.23999254024380234, 1.6938420573965973] 3.8015556173522778\n"
     ]
    }
   ],
   "source": [
    "print(EBLUPNEgen(NE), norm(EBLUPNEgen(NE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=doolse></a>\n",
    "# <font color=brown> NN-DOOLSE or MLE</font>\n",
    "\n",
    "## $\\boldsymbol{1^{st}}$ stage of EBLUP-NE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KKT algorithm\n",
    "using the the KKT algorithm (tab.3, _Hancova et al 2019_)  \n",
    "<img src='KKTscheme.png' width=550 align='left'>  \n",
    "\n",
    "$~$\n",
    ">$\n",
    "\\qquad \\mathbf{q} = \n",
    "\\left(\\begin{array}{c}\n",
    "\\mathbf{e}'  \\mathbf{e}\\\\\n",
    "(\\mathbf{e}'   \\mathbf{v}_{1})^2 \\\\\n",
    "\\vdots \\\\\n",
    "(\\mathbf{e}'   \\mathbf{v}_{l})^2\n",
    "\\end{array}\\right)\n",
    "$\n",
    ">\n",
    "> $\\qquad\\mathrm{G} = \\left(\\begin{array}{ccccc}\n",
    "\\small\n",
    "n^*                  & ||\\mathbf{v}_{1}||^2 & ||\\mathbf{v}_{2}||^2 & \\ldots & ||\\mathbf{v}_{l}||^2 \\\\\n",
    "||\\mathbf{v}_{1}||^2 & ||\\mathbf{v}_{1}||^4 & 0                    & \\ldots & 0 \\\\\n",
    "||\\mathbf{v}_{2}||^2 & 0                    & ||\\mathbf{v}_{2}||^4 & \\ldots & 0 \\\\\n",
    "\\vdots               & \\vdots               & \\vdots               & \\ldots & \\vdots \\\\\n",
    "||\\mathbf{v}_{l}||^2 & 0                    & 0                    & \\ldots & ||\\mathbf{v}_{l}||^4\n",
    "\\end{array}\\right)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy(Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.212000Z",
     "start_time": "2019-05-18T17:59:33.191000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9290879882 2.8882933656 1.6844347381 0.2945109755 1.7860554271] 3.9140125377802595 (1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "## SciPy(Numpy)# Input: form G\n",
    "ns, nvj = n, norm(V, axis=0)\n",
    "u, v, Q  = np.mat(ns), np.mat(nvj**2), np.diag(nvj**4)\n",
    "G = np.bmat([[u,v],[v.T,Q]])\n",
    "# form q\n",
    "e2, Ve2 = ec*e, np.multiply(Vc*e, Vc*e)\n",
    "q = np.vstack((e2, Ve2))\n",
    "\n",
    "# body of the algorithm\n",
    "for b in product([0,1], repeat=l): \n",
    "    # set the KKT-conditions matrix K\n",
    "    K = G*1\n",
    "    for j in range(1,l+1): \n",
    "        if b[j-1] == 0: K[0,j], K[j,j]  = 0,-1\n",
    "    # calculate the auxiliary vector g\n",
    "    g = inv(K)*q\n",
    "    # test non-negativity g\n",
    "    if (g >= 0).all(): break   \n",
    "\n",
    "# Output: Form estimates nu\n",
    "nu = g*1\n",
    "for j in range(1,l+1):\n",
    "    if b[j-1] == 0: nu[j] = 0\n",
    "\n",
    "NN_DOOLSE = np.array(nu).flatten()\n",
    "print(NN_DOOLSE, norm(NN_DOOLSE),b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPY\n",
    "\n",
    "nonnegative DOOLSE as a convex optimization problem\n",
    "\n",
    ">$\n",
    "\\begin{array}{ll} \n",
    "\\textit{minimize}    & f_0(\\boldsymbol{\\nu})=||\\mathbf{e}\\mathbf{e}'-\\Sigma_\\boldsymbol{\\nu}||^2 \\\\[6pt]\n",
    "\\textit{subject to}  & \\boldsymbol{\\nu} = \\left(\\nu_0, \\ldots, \\nu_l\\right)'\\in [0, \\infty)^{l+1} \n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.260000Z",
     "start_time": "2019-05-18T17:59:33.218000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN-DOOLSEcvx = [0.9290879882 2.8882933656 1.6844347381 0.2945109755 1.7860554271] norm = 3.914012537780258\n"
     ]
    }
   ],
   "source": [
    "# set the optimization variable, objective function\n",
    "v = Variable(l+1)\n",
    "fv = sum_squares(e*e.T - v[0]*In - V*diag(v[1:])*Vc)\n",
    "\n",
    "# construct the problem for DOOLSE\n",
    "objective = Minimize(fv)\n",
    "constraints = [v >= 0]\n",
    "prob = Problem(objective,constraints)\n",
    "\n",
    "# solve the DOOLSE problem\n",
    "prob.solve()\n",
    "NN_DOOLSEcvx = v.value\n",
    "print('NN-DOOLSEcvx =', NN_DOOLSEcvx, 'norm =', norm(NN_DOOLSEcvx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPY\n",
    "\n",
    "using equivalent (RE)MLE convex problem (proposition 5, _Hancova et al 2019_)\n",
    "\n",
    "\n",
    ">$\n",
    "\\begin{array}{ll} \n",
    "\\textit{minimize}    & \\quad f_0(\\mathbf{d})=-(n^*\\!-l)\\ln d_0 - \\displaystyle\\sum\\limits_{j=1}^{l} \n",
    "\t\t\\ln(d_0-d_j||\\mathbf{v}_j||^2+d_0\\mathbf{e}'\\mathbf{e}-\\mathbf{e}'\\mathrm{V}\\,\\mathrm{diag}\\{d_j\\}\\mathrm{V}'\\mathbf{e}   \\\\[6pt]\n",
    "\\textit{subject to}  & \\quad d_0 > \\max\\{d_j||\\mathbf{v}_j||^2, j = 1, \\ldots, l\\}  \\\\\n",
    "                     & \\quad d_j \\geq 0, j=1,\\ldots l \\\\\n",
    "                     & \\\\\n",
    "& \\quad\\text{for MLE: } n^* = n, \\text{ for REMLE: } n^* = n-k \\\\\n",
    "\\textit{back transformation:} & \\quad \\nu_0 = \\dfrac{1}{d_0}, \\nu_j = \\dfrac{d_j}{d_0\\left(d_0 -d_j||\\mathbf{v}_j||^2\\right)}\n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.304000Z",
     "start_time": "2019-05-18T17:59:33.264000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMLEcvx =  [0.9290880038938628, 2.88829368749524, 1.6844348207906106, 0.2945109888858931, 1.7860555721581928]  norm =  3.914012881827052\n"
     ]
    }
   ],
   "source": [
    "# set variables for the objective\n",
    "ns = n\n",
    "d = Variable(l+1)\n",
    "logdetS = (ns-l)*log(d[0])+sum(log(d[0]-GV*d[1:]))\n",
    "\n",
    "# construct the problem\n",
    "objective = Maximize(logdetS-(d[0]*ec*e-ec*V*diag(d[1:])*Vc*e))\n",
    "constraints = [0 <= d[1:], max(GV*d[1:]) <= d[0]]\n",
    "prob = Problem(objective,constraints)\n",
    "\n",
    "# solve the problem\n",
    "solution = prob.solve()\n",
    "dv = d.value.tolist()\n",
    "\n",
    "# back transformation\n",
    "s0 = [1/dv[0]]\n",
    "sj = [dv[i]/(dv[0]*(dv[0]-dv[i]*GV[i-1,i-1])) for i in range(1,l+1)]\n",
    "sv = s0+sj\n",
    "\n",
    "print('REMLEcvx = ', sv, ' norm = ', norm(sv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\boldsymbol{2^{nd}}$ stage of EBLUP-NE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy(Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.317000Z",
     "start_time": "2019-05-18T17:59:33.309000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0.948468878619636, 0.914042121526222, 0.6270020070281175, 0.9186300760117448]\n"
     ]
    }
   ],
   "source": [
    "## SciPy(Numpy)# numerical results\n",
    "print(rho2(NN_DOOLSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.333000Z",
     "start_time": "2019-05-18T17:59:33.323000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0930446920400416, 2.8128906231460333, 1.6104130979046416, 0.23320397549916197, 1.7118482468229341] 3.832145510914477\n"
     ]
    }
   ],
   "source": [
    "print(EBLUPNE(NN_DOOLSE), norm(EBLUPNE(NN_DOOLSE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.348000Z",
     "start_time": "2019-05-18T17:59:33.339000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0930446920400416, 2.812890623146028, 1.6104130979046454, 0.23320397549916147, 1.7118482468229304] 3.8321455109144735\n"
     ]
    }
   ],
   "source": [
    "#cross-checking\n",
    "print(EBLUPNEgen(NN_DOOLSE), norm(EBLUPNEgen(NN_DOOLSE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=mdoolse></a>\n",
    "# <font color=brown> NN-MDOOLSE or REMLE</font>\n",
    "using the KKT algorithm (tab.3, _Hancova et al 2019_)\n",
    "\n",
    "## $\\boldsymbol{1^{st}}$ stage of EBLUP-NE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KKT algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy(Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.381000Z",
     "start_time": "2019-05-18T17:59:33.353000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.093044692  2.874630307  1.6707716794 0.2808479168 1.7723923684] 3.93318882910389 (1, 1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Input: form G\n",
    "ns, nvj = n-k, norm(V, axis=0)\n",
    "u, v, Q  = np.mat(ns), np.mat(nvj**2), np.diag(nvj**4)\n",
    "G = np.bmat([[u,v],[v.T,Q]])\n",
    "# form q\n",
    "e2, Ve2 = ec*e, np.multiply(Vc*e, Vc*e)\n",
    "q = np.vstack((e2, Ve2))\n",
    "\n",
    "# body of the algorithm\n",
    "for b in product([0,1], repeat=l): \n",
    "    # set the KKT-conditions matrix K\n",
    "    K = G*1\n",
    "    for j in range(1,l+1): \n",
    "        if b[j-1] == 0: K[0,j], K[j,j]  = 0,-1\n",
    "    # calculate the auxiliary vector g\n",
    "    g = inv(K)*q\n",
    "    # test non-negativity g\n",
    "    if (g >= 0).all(): break   \n",
    "\n",
    "# Output: Form estimates nu\n",
    "nu = g*1\n",
    "for j in range(1,l+1):\n",
    "    if b[j-1] == 0: nu[j] = 0\n",
    "\n",
    "NN_MDOOLSE = np.array(nu).flatten()\n",
    "print(NN_MDOOLSE, norm(NN_MDOOLSE),b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPY\n",
    "\n",
    "nonnegative DOOLSE as a convex optimization problem\n",
    "\n",
    ">$\n",
    "\\begin{array}{ll} \n",
    "\\textit{minimize}    & f_0(\\boldsymbol{\\nu})=||\\mathbf{e}\\mathbf{e}'-\\mathrm{M_F}\\Sigma_\\boldsymbol{\\nu}\\mathrm{M_F}||^2 \\\\[6pt]\n",
    "\\textit{subject to}  & \\boldsymbol{\\nu} = \\left(\\nu_0, \\ldots, \\nu_l\\right)'\\in [0, \\infty)^{l+1} \n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.423000Z",
     "start_time": "2019-05-18T17:59:33.386000Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN_MDOOLSEcvx = [1.093044692  2.874630307  1.6707716794 0.2808479168 1.7723923684] norm = 3.933188829103891\n"
     ]
    }
   ],
   "source": [
    "# set the optimization variable, objective function\n",
    "v = Variable(l+1)\n",
    "fv = sum_squares(e*e.T - v[0]*MF - V*diag(v[1:])*V.T)\n",
    "\n",
    "# construct the problem for DOOLSE\n",
    "objective = Minimize(fv)\n",
    "constraints = [v >= 0]\n",
    "prob = Problem(objective,constraints)\n",
    "\n",
    "# solve the DOOLSE problem\n",
    "prob.solve()\n",
    "\n",
    "NN_MDOOLSEcvx = v.value\n",
    "print('NN_MDOOLSEcvx =', NN_MDOOLSEcvx, 'norm =', norm(NN_MDOOLSEcvx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVXPY\n",
    "\n",
    "using equivalent (RE)MLE convex problem (proposition 5, _Hancova et al 2019_)\n",
    "\n",
    "\n",
    ">$\n",
    "\\begin{array}{ll} \n",
    "\\textit{minimize}    & \\quad f_0(\\mathbf{d})=-(n^*\\!-l)\\ln d_0 - \\displaystyle\\sum\\limits_{j=1}^{l} \n",
    "\t\t\\ln(d_0-d_j||\\mathbf{v}_j||^2+d_0\\mathbf{e}'\\mathbf{e}-\\mathbf{e}'\\mathrm{V}\\,\\mathrm{diag}\\{d_j\\}\\mathrm{V}'\\mathbf{e}   \\\\[6pt]\n",
    "\\textit{subject to}  & \\quad d_0 > \\max\\{d_j||\\mathbf{v}_j||^2, j = 1, \\ldots, l\\}  \\\\\n",
    "                     & \\quad d_j \\geq 0, j=1,\\ldots l \\\\\n",
    "                     & \\\\\n",
    "& \\quad\\text{for MLE: } n^* = n, \\text{ for REMLE: } n^* = n-k \\\\\n",
    "\\textit{back transformation:} & \\quad \\nu_0 = \\dfrac{1}{d_0}, \\nu_j = \\dfrac{d_j}{d_0\\left(d_0 -d_j||\\mathbf{v}_j||^2\\right)}\n",
    "\\end{array}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.476000Z",
     "start_time": "2019-05-18T17:59:33.429000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMLEcvx =  [1.0930447242722945, 2.8746310598648552, 1.6707717650044684, 0.28084791305652057, 1.7723924736577228]  norm =  3.933189471825903\n"
     ]
    }
   ],
   "source": [
    "# set variables for the objective\n",
    "ns = n - k\n",
    "d = Variable(l+1)\n",
    "logdetS = (ns-l)*log(d[0])+sum(log(d[0]-GV*d[1:]))\n",
    "\n",
    "# construct the problem\n",
    "objective = Maximize(logdetS-(d[0]*ec*e-ec*V*diag(d[1:])*Vc*e))\n",
    "constraints = [0 <= d[1:], max(GV*d[1:]) <= d[0]]\n",
    "prob = Problem(objective,constraints)\n",
    "\n",
    "# solve the problem\n",
    "solution = prob.solve()\n",
    "dv = d.value.tolist()\n",
    "\n",
    "# back transformation\n",
    "s0 = [1/dv[0]]\n",
    "sj = [dv[i]/(dv[0]*(dv[0]-dv[i]*GV[i-1,i-1])) for i in range(1,l+1)]\n",
    "sv = s0+sj\n",
    "\n",
    "print('REMLEcvx = ', sv, ' norm = ', norm(sv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\boldsymbol{2^{nd}}$ stage of EBLUP-NE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy(Numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.491000Z",
     "start_time": "2019-05-18T17:59:33.481000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0.9395166476180283, 0.8992740085016775, 0.5701752693307878, 0.9046290672634771]\n"
     ]
    }
   ],
   "source": [
    "# numerical results\n",
    "print(rho2(NN_MDOOLSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.507000Z",
     "start_time": "2019-05-18T17:59:33.495000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0930446920400416, 2.786340836212267, 1.5843937689416052, 0.2120681242624512, 1.6857576550762208] 3.7888649131868295\n"
     ]
    }
   ],
   "source": [
    "print(EBLUPNE(NN_MDOOLSE),norm(EBLUPNE(NN_MDOOLSE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-18T17:59:33.521000Z",
     "start_time": "2019-05-18T17:59:33.513000Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0930446920400416, 2.786340836212269, 1.584393768941593, 0.21206812426244862, 1.6857576550762141] 3.788864913186823\n"
     ]
    }
   ],
   "source": [
    "#cross-checking\n",
    "print(EBLUPNEgen(NN_MDOOLSE), norm(EBLUPNEgen(NN_MDOOLSE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=references></a>\n",
    "# <font color=brown> References </font>\n",
    "This notebook belongs to suplementary materials of the paper submitted to Statistical Papers and available at <https://arxiv.org/abs/1905.07771>.\n",
    "\n",
    "* Hančová, M., Vozáriková, G., Gajdoš, A., Hanč, J. (2019). [Estimating variance components in time series\n",
    "\tlinear regression models using empirical BLUPs and convex optimization](https://arxiv.org/abs/1905.07771), https://arxiv.org/, 2019.  \n",
    "\n",
    "### Abstract of the paper\n",
    "\n",
    "We propose a two-stage estimation method of variance components in time series models known as FDSLRMs, whose observations can be described by a linear mixed model (LMM). We based estimating variances, fundamental quantities in a time series forecasting approach called kriging, on the empirical (plug-in) best linear unbiased predictions of unobservable random components in FDSLRM. \n",
    "\n",
    "The method, providing invariant non-negative quadratic estimators, can be used for any absolutely continuous probability distribution of time series data. As a result of applying the convex optimization and the LMM methodology, we resolved two problems $-$ theoretical existence and equivalence between least squares estimators, non-negative (M)DOOLSE, and maximum likelihood estimators, (RE)MLE, as possible starting points of our method and a \n",
    "practical lack of computational implementation for FDSLRM. As for computing (RE)MLE in the case of $ n $ observed time series values, we also discovered a new algorithm of order $\\mathcal{O}(n)$, which at the default precision is $10^7$ times more accurate and $n^2$ times faster than the best current Python(or R)-based computational packages, namely CVXPY, CVXR, nlme, sommer and mixed. \n",
    "\n",
    "We illustrate our results on three real data sets $-$ electricity consumption, tourism and cyber security $-$ which are easily available, reproducible, sharable and modifiable in the form of interactive Jupyter notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Štulajter, F., Witkovský, V. (2004). [Estimation of Variances in Orthogonal Finite\n",
    "Discrete Spectrum Linear Regression Models](https://link.springer.com/article/10.1007/s001840300299). _Metrika_, 2004, Vol. 60, No. 2, pp. 105–118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| [Table of Contents](#table_of_contents) | [Data and model](#data_and_model) | [Natural estimators](#natural_estimators) |  [NN-DOOLSE, MLE](#doolse) | [NN-MDOOLSE, REMLE](#mdoolse) | [References](#references) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2.7",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
